{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# docker构建镜像\n",
    "----------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "解决1：\n",
    "Dockerfile\n",
    "\n",
    "# This vision_insight Dockerfile\n",
    "# Version 1.0\n",
    "\n",
    "# Base images 基础镜像\n",
    "FROM nvidia/cuda:10.0-runtime-centos7\n",
    "# MAINTAINER 维护者信息\n",
    "MAINTAINER Joshua\n",
    "\n",
    "# RUN 执行以下命令\n",
    "RUN mkdir -p /data/deploy/sv-keyphrase-tag/server/\n",
    "RUN mkdir -p /data/deploy/sv-keyphrase-tag/server/resources/rbtl3/\n",
    "COPY ./server /data/deploy/sv-keyphrase-tag/server/\n",
    "COPY ./check.sh /\n",
    "COPY ./libstdc++.so.6.0.25 /\n",
    "RUN yum install gcc libffi-devel python-devel openssl-devel -y --skip-broken\n",
    "RUN pip3 install --upgrade pip\n",
    "RUN pip3 install -r /data/deploy/sv-keyphrase-tag/server/requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "RUN rm -fr /usr/local/lib64/python3.6/site-packages/paddle*\n",
    "RUN pip3 install paddlepaddle-gpu==2.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "ENV LANG \"en_US.UTF-8\"\n",
    "RUN chmod -R 777 /data/deploy/sv-keyphrase-tag/server/*\n",
    "RUN chmod -R 777 /check.sh\n",
    "# 启动服务\n",
    "#CMD [\"/bin/bash\", \"-c\", \"/data/deploy/sv-keyphrase-tag/server/start.sh\"]\n",
    "\n",
    "\n",
    "解决2：\n",
    "Dockerfile\n",
    "\n",
    "# This vision_insight Dockerfile\n",
    "# Version 1.0\n",
    "\n",
    "# Base images 基础镜像\n",
    "FROM nvidia/cuda:10.0-runtime-centos7\n",
    "# MAINTAINER 维护者信息\n",
    "MAINTAINER Joshua\n",
    "\n",
    "# RUN 执行以下命令\n",
    "RUN mkdir -p /data/deploy/query_intention_server/server/\n",
    "COPY ./server /data/deploy/query_intention_server/server/\n",
    "COPY ./check.sh /\n",
    "\n",
    "COPY ./libstdc++.so.6.0.25 /usr/lib64/libstdc++.so.6.0.25\n",
    "RUN rm -rf /usr/lib64/libstdc++.so.6\n",
    "RUN ln -s /usr/lib64/libstdc++.so.6.0.25 /usr/lib64/libstdc++.so.6\n",
    "\n",
    "\n",
    "RUN yum install -y vim git less \\\n",
    "    && pip3 install torch==1.7.1   --extra-index-url https://download.pytorch.org/whl/cpu \\\n",
    "    && pip3 install -r /data/deploy/query_intention_server/server/requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "\n",
    "ENV LANG \"en_US.UTF-8\"\n",
    "RUN chmod -R 777 /data/deploy/query_intention_server/server/*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# docker编译\n",
    "----------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "解决：\n",
    "## GPU版本\n",
    "docker build -t keyphrase_tag:v0 --no-cache .\n",
    "\n",
    "docker run -it --name=keyphrase_predict --ipc=host --net=host --privileged=true --runtime=nvidia -v /video_online/cpp_thirdparty/cuda/lib64:/usr/local/cuda/lib64 -v /video_online/python_model/new_words_tag_model/rbtl3:/data/deploy/sv-keyphrase-tag/server/resources/rbtl3 -v /video_online/log_server_online/keyphrase_tag_log:/data/deploy/sv-new-words-tag/server/logs --shm-size 16g  -p 4070:4070 -p 4071:4071 -e NVIDIA_VISIBLE_DEVICES=all -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,video keyphrase_tag:v0 bash\n",
    "\n",
    "docker start keyphrase_predict\n",
    "docker exec -ti keyphrase_predict /bin/bash\n",
    "\n",
    "\n",
    "## CPU版本\n",
    "\n",
    "docker build -t query_intention:v0 --no-cache .\n",
    "\n",
    "docker run -it --name=query_intention --ipc=host --net=host --privileged=true  -v /mnt/video_online_juicefs/python_model/text_retrieval_models:/data/deploy/models -v /mnt/video_online_juicefs/config_online/bid_config:/data/bid_config -v /mnt/video_online_juicefs/log_server_online/query_intention_server_log:/data/deploy/query_intention_server/server/log --shm-size 32g  -p 7002:7002 query_intention:v0 bash\n",
    "\n",
    "\"/bin/sh\" \"-c\" \"/data/deploy/query_intention_server/start.sh  1 data/config.yaml ; tail -f /dev/null\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 大模型llm镜像构建"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docker build -t chatglm2:v0 --no-cache .\n",
    "docker run --gpus all --ipc=host --ulimit memlock=-1 -v `pwd`/models:/app/models/chatglm2 -p 7860:7860 -it --rm chatglm2:v0\n",
    "\n",
    "docker run -it --ipc=host --ulimit memlock=-1 --runtime=nvidia  -e NVIDIA_VISIBLE_DEVICES=all -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,video -v `pwd`/models/chatglm2-6b:/app/models/chatglm2 -p 6868:6868 chatglm2:v0 bash"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
