{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "启动spark-shell\n",
    "----------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "解决：\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "/usr/bin/spark2-shell \\\n",
    "--master yarn \\\n",
    "--deploy-mode client \\\n",
    "--queue root.dataming.prd \\\n",
    "--driver-memory 10g \\\n",
    "--num-executors 100 \\\n",
    "--executor-memory 16g \\\n",
    "--executor-cores 1 \\\n",
    "--conf spark.port.maxRetries=100 \\\n",
    "--conf spark.driver.maxResultSize=6g \\\n",
    "--conf spark.hadoop.validateOutputSpecs=false \\\n",
    "-conf spark.executor.memoryOverhead=8g \\\n",
    "--jars /home/xx/online_lib/libs/fastjson-1.2.62.jar,/home/xx/online_lib/libs/httpclient-4.5.13.jar,/home/xx/online_lib/libs/httpcore-4.4.13.jar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "启动pyspark-shell\n",
    "----------------------------------\n",
    "https://mopheiok.github.io/spark/PySpark-on-Yarn/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "解决：\n",
    "\n",
    "## cluster模式脚本\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "#export PYSPARK_DRIVER_PYTHON=./env/miniconda3/bin/python\n",
    "#export PYSPARK_PYTHON=/home/xx/miniconda3/bin/python\n",
    "/usr/bin/pyspark3 --master yarn \\\n",
    "  --deploy-mode cluster \\\n",
    "  --queue root.dataming.dev \\\n",
    "  --driver-memory 16g \\\n",
    "  --conf spark.locality.wait=5 \\\n",
    "  --executor-memory 8g \\\n",
    "  --executor-cores 1 \\\n",
    "  --num-executors 150 \\\n",
    "  --conf spark.kryoserializer.buffer.max=256m \\\n",
    "  --conf spark.kryoserializer.buffer=64m \\\n",
    "  --conf spark.port.maxRetries=100 \\\n",
    "  --conf spark.driver.maxResultSize=10g \\\n",
    "  --conf spark.executor.memoryOverhead=5g \\\n",
    "  --archives hdfs://hdfs_config/nlp/zs/config/anaconda.tar.gz#env \\\n",
    "  --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=.env/miniconda3/bin/python \\\n",
    "  --name shell_dev\n",
    "\n",
    "\n",
    "## client模式脚本\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "#export PYSPARK_DRIVER_PYTHON=./env/miniconda3/bin/python\n",
    "export PYSPARK_PYTHON=/home/xx/miniconda3/bin/python\n",
    "/usr/bin/pyspark2 --master yarn \\\n",
    "  --deploy-mode client \\\n",
    "  --queue root.dataming.dev \\\n",
    "  --driver-memory 16g \\\n",
    "  --conf spark.locality.wait=5 \\\n",
    "  --executor-memory 8g \\\n",
    "  --executor-cores 1 \\\n",
    "  --num-executors 150 \\\n",
    "  --conf spark.kryoserializer.buffer.max=256m \\\n",
    "  --conf spark.kryoserializer.buffer=64m \\\n",
    "  --conf spark.port.maxRetries=100 \\\n",
    "  --conf spark.driver.maxResultSize=10g \\\n",
    "  --conf spark.executor.memoryOverhead=5g \\\n",
    "  --conf spark.pyspark.driver.python=/home/xx/miniconda3/bin/python \\\n",
    "  --archives hdfs://hdfs_config/nlp/zs/config/anaconda.tar.gz#env \\\n",
    "  --conf spark.pyspark.python=./env/miniconda3/bin/python \\\n",
    "  --name shell_dev"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
